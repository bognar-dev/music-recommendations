{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfnDcTrf9zMd"
      },
      "source": [
        "# Album Cover Music Recommendation System\n",
        "\n",
        "## Step 1: Project Setup and Data Loading\n",
        "\n",
        "A CSV file is required for this project, containing at least the following columns:\n",
        "\n",
        "- **`song_name`**: The title of the song.\n",
        "- **`img`**: A URL pointing to the album cover image.\n",
        "\n",
        "The file (e.g., `music_dataset.csv`) should be placed in the working directory. This dataset will be used for analyzing album cover images and generating music recommendations.\n",
        "\n",
        "### Required Libraries\n",
        "\n",
        "The following libraries are necessary for the implementation:\n",
        "\n",
        "- **`pandas`** and **`numpy`**: For data manipulation.\n",
        "- **`scikit-learn`**: For preprocessing and similarity calculations.\n",
        "- **`tensorflow`** and **`keras`**: For deep learning-based feature extraction.\n",
        "- **`opencv-python-headless`**: For image processing.\n",
        "- **`pillow`**: For handling image operations.\n",
        "- **`matplotlib`** and **`seaborn`**: For data visualization.\n",
        "\n",
        "### Loading the Dataset\n",
        "\n",
        "After ensuring the required libraries are installed, the dataset is loaded into a DataFrame. Basic checks can then be performed to confirm the structure and contents of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N43_PA-P9N8j",
        "outputId": "9f5a273f-8bb7-467b-b1d9-6364a9efdd96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "                               name      artist              spotify_id  \\\n",
            "0            Mood (feat. iann dior)    24kGoldn  3tjFYV6RSFtuktYl3ZtYcq   \n",
            "2                          Dynamite         BTS  0t1kP63rueHleOhQkYSXFY   \n",
            "6                             Hawái      Maluma  4uoR6qeWeuL4Qeu2qJzkuG   \n",
            "8  Savage Love (Laxed - Siren Beat)   Jawsh 685  1xQ6trAsedVPCdbtDAmk0c   \n",
            "9         Head & Heart (feat. MNEK)  Joel Corry  6cx06DFPPHchuUAcTxznu9   \n",
            "\n",
            "                                             preview  \\\n",
            "0  https://p.scdn.co/mp3-preview/45cb08fdb67744ab...   \n",
            "2  https://p.scdn.co/mp3-preview/a707728846c105f4...   \n",
            "6  https://p.scdn.co/mp3-preview/07037d916c2e4ea2...   \n",
            "8  https://p.scdn.co/mp3-preview/d709526bcdffa668...   \n",
            "9  https://p.scdn.co/mp3-preview/a860b3fe04f48053...   \n",
            "\n",
            "                                                 img  danceability  energy  \\\n",
            "0  https://i.scdn.co/image/ab67616d0000b273ff8c98...         0.700   0.722   \n",
            "2  https://i.scdn.co/image/ab67616d0000b273755995...         0.746   0.765   \n",
            "6  https://i.scdn.co/image/ab67616d0000b273480552...         0.787   0.728   \n",
            "8  https://i.scdn.co/image/ab67616d0000b273e3eb3b...         0.767   0.481   \n",
            "9  https://i.scdn.co/image/ab67616d0000b27391e93c...         0.734   0.874   \n",
            "\n",
            "   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
            "0    -3.558       0.0369        0.2210          0.000000    0.2720    0.756   \n",
            "2    -4.410       0.0993        0.0112          0.000000    0.0936    0.737   \n",
            "6    -3.455       0.3890        0.1890          0.000023    0.0629    0.545   \n",
            "8    -8.520       0.0803        0.2340          0.000000    0.2690    0.761   \n",
            "9    -3.158       0.0662        0.1680          0.000011    0.0489    0.905   \n",
            "\n",
            "   acousticness_artist  danceability_artist  energy_artist  \\\n",
            "0             0.118269             0.731588       0.681235   \n",
            "2             0.099350             0.614798       0.786452   \n",
            "6             0.200861             0.741490       0.759686   \n",
            "8             0.116467             0.746333       0.573667   \n",
            "9             0.094600             0.697000       0.921000   \n",
            "\n",
            "   instrumentalness_artist  liveness_artist  speechiness_artist  \\\n",
            "0                 0.000002         0.160000            0.123765   \n",
            "2                 0.000044         0.202608            0.128515   \n",
            "6                 0.000088         0.156502            0.120922   \n",
            "8                 0.461333         0.301667            0.100100   \n",
            "9                 0.000019         0.159000            0.042400   \n",
            "\n",
            "   valence_artist  \n",
            "0        0.566824  \n",
            "2        0.533369  \n",
            "6        0.707190  \n",
            "8        0.893000  \n",
            "9        0.722000  \n",
            "\n",
            "Total number of songs: 47397\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn tensorflow keras opencv-python-headless pillow matplotlib seaborn\n",
        "\n",
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Deep learning and image processing\n",
        "from tensorflow.keras.applications import ResNet50V2, VGG16\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('spotify_dataset.csv').dropna()\n",
        "\n",
        "# Check dataset\n",
        "print(df.head())\n",
        "print(\"\\nTotal number of songs:\", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOyffBCa-K4d"
      },
      "source": [
        "## Step 2: Image Download and Preprocessing\n",
        "\n",
        "To analyze album covers, it is necessary to download images from the provided URLs and prepare them for feature extraction. This involves implementing functions for downloading images and applying preprocessing steps to make them suitable for analysis.\n",
        "\n",
        "### Key Functions\n",
        "\n",
        "1. **Image Download**  \n",
        "   A function to download images from the URLs provided in the dataset. The images are saved locally for subsequent processing.\n",
        "\n",
        "2. **Preprocessing**  \n",
        "   The downloaded images undergo preprocessing to ensure they meet the input requirements of the feature extraction methods. This may include resizing and color space conversion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "equbHSNF-fgc"
      },
      "outputs": [],
      "source": [
        "def download_image(url, filename):\n",
        "    \"\"\"\n",
        "    Download image from URL and save locally\n",
        "    \"\"\"\n",
        "    import requests\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmRHvbX--jXf"
      },
      "source": [
        "## Step 3: Feature Extraction\n",
        "\n",
        "Various features are extracted from the album cover images to enable effective recommendation generation. The features include:\n",
        "\n",
        "### 1. Color Histograms\n",
        "   - Color histograms capture the distribution of colors in an image, providing a representation of the color composition. This is done by converting the image to the HSV color space and computing the histogram for the hue and saturation channels.\n",
        "\n",
        "### 2. CNN Features\n",
        "   - Convolutional Neural Networks (CNNs) such as **ResNet** and **VGG** are used to extract high-level image features. These models are pre-trained on large datasets (e.g., ImageNet) and can identify complex patterns in images. The extracted features represent the album cover in a way that can be compared across songs.\n",
        "\n",
        "### 3. Font Features (Optional)\n",
        "   - Font features involve analyzing any text on the album cover. This can be done using **pytesseract**, an OCR tool, to extract text and derive basic text-based features (e.g., text length, word count). This step is optional and requires the installation of **pytesseract**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zEYHgHMp-vz2"
      },
      "outputs": [],
      "source": [
        "def extract_color_histogram(image_path):\n",
        "    \"\"\"\n",
        "    Extract color histogram features from an image\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    # Convert to HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Compute histogram\n",
        "    hist = cv2.calcHist([hsv_image], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()\n",
        "\n",
        "\n",
        "def extract_cnn_features_sequential(image_path, model_name='resnet'):\n",
        "    \"\"\"\n",
        "    Extract deep features using pre-trained CNN models sequentially to avoid memory overload.\n",
        "    \"\"\"\n",
        "    # Resize image\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Select and preprocess model\n",
        "    if model_name.lower() == 'resnet':\n",
        "        model = ResNet50V2(weights='imagenet', include_top=False, pooling='avg')\n",
        "        preprocessed_img = resnet_preprocess(img_array)\n",
        "    else:\n",
        "        model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
        "        preprocessed_img = vgg_preprocess(img_array)\n",
        "\n",
        "    # Expand dimensions and predict\n",
        "    preprocessed_img = np.expand_dims(preprocessed_img, axis=0)\n",
        "    features = model.predict(preprocessed_img)\n",
        "\n",
        "    # Free up memory by clearing the Keras session\n",
        "    from tensorflow.keras import backend as K\n",
        "    K.clear_session()\n",
        "\n",
        "    return features.flatten()\n",
        "\n",
        "\n",
        "def extract_font_features(image_path):\n",
        "    \"\"\"\n",
        "    Basic font feature extraction\n",
        "    \"\"\"\n",
        "    import pytesseract\n",
        "\n",
        "    # Read image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform text extraction\n",
        "    text = pytesseract.image_to_string(gray)\n",
        "\n",
        "    # Basic text analysis features\n",
        "    return {\n",
        "        'text_length': len(text),\n",
        "        'word_count': len(text.split()),\n",
        "        'unique_chars': len(set(text))\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_album_cover_features_sequential(image_url):\n",
        "    \"\"\"\n",
        "    Comprehensive feature extraction for album covers, processed sequentially.\n",
        "    \"\"\"\n",
        "    # Create temp directory if not exists\n",
        "    os.makedirs('temp_covers', exist_ok=True)\n",
        "\n",
        "    # Generate unique filename\n",
        "    filename = f\"temp_covers/{hash(image_url)}.jpg\"\n",
        "\n",
        "    # Download image\n",
        "    if not download_image(image_url, filename):\n",
        "        return None\n",
        "\n",
        "    # Extract features sequentially to avoid memory overload\n",
        "    features = {\n",
        "        'color_hist': extract_color_histogram(filename)\n",
        "    }\n",
        "\n",
        "    # Process ResNet features first\n",
        "    features['resnet_features'] = extract_cnn_features_sequential(filename, model_name='resnet')\n",
        "\n",
        "    # Process VGG features next\n",
        "    features['vgg_features'] = extract_cnn_features_sequential(filename, model_name='vgg')\n",
        "\n",
        "    # Optional font features (requires pytesseract)\n",
        "    try:\n",
        "        features['font_features'] = extract_font_features(filename)\n",
        "    except ImportError:\n",
        "        print(\"Pytesseract not installed. Skipping font features.\")\n",
        "\n",
        "    return features\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "\n",
        "def process_dataset_features(dataframe, output_file='album_features.pkl', techniques=None):\n",
        "    \"\"\"\n",
        "    Process features for the entire dataset, with options to select specific techniques.\n",
        "    \"\"\"\n",
        "    # Default techniques to run if none are provided\n",
        "    if techniques is None:\n",
        "        techniques = ['color_hist', 'resnet', 'vgg', 'font']\n",
        "\n",
        "    features_list = []\n",
        "    total_songs = len(dataframe)\n",
        "\n",
        "    # Check if file already exists, and load features if so\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Loading existing features from {output_file}...\")\n",
        "        with open(output_file, 'rb') as f:\n",
        "            features_list = pickle.load(f)\n",
        "        return pd.DataFrame(features_list)\n",
        "\n",
        "    # Loop through each song and extract selected features\n",
        "    for idx, row in dataframe.iterrows():  # Iterate through rows using iterrows()\n",
        "        url = row['img']\n",
        "        features = {}\n",
        "\n",
        "        # Create temp directory if not exists\n",
        "        os.makedirs('temp_covers', exist_ok=True)\n",
        "\n",
        "        # Generate unique filename\n",
        "        filename = f\"temp_covers/{hash(url)}.jpg\"\n",
        "\n",
        "        # Download image\n",
        "        if not download_image(url, filename):\n",
        "            continue  # Skip if download fails\n",
        "\n",
        "        if 'color_hist' in techniques:\n",
        "            features['color_hist'] = extract_color_histogram(filename) # Pass filename\n",
        "        if 'resnet' in techniques:\n",
        "            features['resnet_features'] = extract_cnn_features_sequential(filename, 'resnet') # Pass filename\n",
        "        if 'vgg' in techniques:\n",
        "            features['vgg_features'] = extract_cnn_features_sequential(filename, 'vgg') # Pass filename\n",
        "        if 'font' in techniques:\n",
        "            try:\n",
        "                features['font_features'] = extract_font_features(filename) # Pass filename\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting font features for {url}: {e}\")\n",
        "\n",
        "        if features:  # Only append if features were extracted\n",
        "            features['song_name'] = row['name']  # Include song name\n",
        "            features_list.append(features)\n",
        "\n",
        "        # Print progress every 10 songs or at the last song\n",
        "        if idx % 10 == 0 or idx == total_songs - 1:\n",
        "            print(f\"Processing song {idx + 1} of {total_songs}\")\n",
        "\n",
        "    # Save features list to a file\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(features_list, f)\n",
        "        print(f\"Features saved to {output_file}\")\n",
        "\n",
        "    return pd.DataFrame(features_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB7_Ae0h-5Z-"
      },
      "source": [
        "## Step 4: Similarity Calculation and Recommendations\n",
        "\n",
        "To recommend songs based on album cover similarity, cosine similarity is used to measure how similar the features of one album cover are to another. The following two functions are implemented for recommendation generation:\n",
        "\n",
        "### 1. recommend_songs_by_cover\n",
        "   - This function recommends songs that have similar album covers to a given target song. It calculates the cosine similarity between the features of the target song and all other songs in the dataset, then returns the top N most similar songs based on their album cover features.\n",
        "\n",
        "### 2. create_playlist_recommendation\n",
        "   - This function generates song recommendations based on the collective characteristics of a playlist. The average features of the songs in the playlist are calculated, and then cosine similarity is used to find songs that are most similar to this average. The top N recommended songs are returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "edgJzMOH-5wA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def recommend_songs_by_cover(target_song, features_df, top_n=5, available_features=None):\n",
        "    \"\"\"\n",
        "    Recommend songs based on album cover similarity, considering only the features available.\n",
        "    \"\"\"\n",
        "    print(\"Feature dataframe\")\n",
        "    print(features_df.head())\n",
        "    print(\"Available features\")\n",
        "    print(available_features)\n",
        "    # Get target song features\n",
        "    target_features = features_df[features_df['song_name'] == target_song].iloc[0]\n",
        "\n",
        "    similarities = {}\n",
        "\n",
        "    # Compute similarities for available features\n",
        "    if 'color_hist' in available_features and 'color_hist' in target_features:\n",
        "        similarities['color_similarity'] = cosine_similarity(\n",
        "            target_features['color_hist'].reshape(1, -1),\n",
        "            features_df['color_hist'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    if 'resnet' in available_features and 'resnet_features' in target_features:\n",
        "        similarities['resnet_similarity'] = cosine_similarity(\n",
        "            target_features['resnet_features'].reshape(1, -1),\n",
        "            features_df['resnet_features'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    if 'vgg' in available_features and 'vgg_features' in target_features:\n",
        "        similarities['vgg_similarity'] = cosine_similarity(\n",
        "            target_features['vgg_features'].reshape(1, -1),\n",
        "            features_df['vgg_features'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    # Aggregate similarities\n",
        "    if similarities:\n",
        "        aggregate_similarity = np.mean(list(similarities.values()), axis=0)\n",
        "\n",
        "        # Remove target song from recommendations\n",
        "        aggregate_similarity[features_df['song_name'] == target_song] = -1\n",
        "\n",
        "        # Get top N recommendations\n",
        "        top_indices = aggregate_similarity.argsort()[-top_n:][::-1]\n",
        "\n",
        "        return features_df.iloc[top_indices]\n",
        "    else:\n",
        "        print(\"No available features for similarity calculation.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def create_playlist_recommendation(playlist, features_df, top_n=10, available_features=None):\n",
        "    \"\"\"\n",
        "    Generate recommendations based on playlist, considering only the features available.\n",
        "    \"\"\"\n",
        "    # Compute average features of playlist\n",
        "    playlist_features = features_df[features_df['song_name'].isin(playlist)]\n",
        "\n",
        "    avg_features = {}\n",
        "\n",
        "    # Compute average for each available feature\n",
        "    if 'color_hist' in available_features:\n",
        "        avg_features['color_hist'] = np.mean(playlist_features['color_hist'].tolist(), axis=0)\n",
        "\n",
        "    if 'resnet' in available_features:\n",
        "        avg_features['resnet_features'] = np.mean(playlist_features['resnet_features'].tolist(), axis=0)\n",
        "\n",
        "    if 'vgg' in available_features:\n",
        "        avg_features['vgg_features'] = np.mean(playlist_features['vgg_features'].tolist(), axis=0)\n",
        "\n",
        "    similarities = {}\n",
        "\n",
        "    # Compute similarities for available features\n",
        "    if 'color_hist' in available_features and 'color_hist' in avg_features:\n",
        "        similarities['color_similarity'] = cosine_similarity(\n",
        "            avg_features['color_hist'].reshape(1, -1),\n",
        "            features_df['color_hist'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    if 'resnet' in available_features and 'resnet_features' in avg_features:\n",
        "        similarities['resnet_similarity'] = cosine_similarity(\n",
        "            avg_features['resnet_features'].reshape(1, -1),\n",
        "            features_df['resnet_features'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    if 'vgg' in available_features and 'vgg_features' in avg_features:\n",
        "        similarities['vgg_similarity'] = cosine_similarity(\n",
        "            avg_features['vgg_features'].reshape(1, -1),\n",
        "            features_df['vgg_features'].tolist()\n",
        "        )[0]\n",
        "\n",
        "    # Aggregate similarities\n",
        "    if similarities:\n",
        "        aggregate_similarity = np.mean(list(similarities.values()), axis=0)\n",
        "\n",
        "        # Remove playlist songs from recommendations\n",
        "        aggregate_similarity[features_df['song_name'].isin(playlist)] = -1\n",
        "\n",
        "        # Get top N recommendations\n",
        "        top_indices = aggregate_similarity.argsort()[-top_n:][::-1]\n",
        "\n",
        "        return features_df.iloc[top_indices]\n",
        "    else:\n",
        "        print(\"No available features for similarity calculation.\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djgnUZQb--LC"
      },
      "source": [
        "## Step 5: Example Usage\n",
        "\n",
        "To test the recommendation system, the following examples demonstrate how to generate song recommendations based on album cover similarity:\n",
        "\n",
        "### 1. Process Dataset Features\n",
        "   - Extract features for all the album covers in the dataset using the `process_dataset_features` function. This will generate the feature matrix required for similarity calculations.\n",
        "\n",
        "### 2. Recommend Songs for a Single Song\n",
        "   - Use the `recommend_songs_by_cover` function to get song recommendations based on a specific song. The name of the target song is provided, and the function will return the top N most similar songs.\n",
        "\n",
        "### 3. Recommend Songs Based on a Playlist\n",
        "   - Use the `create_playlist_recommendation` function to recommend songs based on a playlist. A playlist consisting of song names is provided, and the function will return songs similar to the collective characteristics of the playlist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nATepNiA-9ql",
        "outputId": "4ca5ef9a-0267-476c-a843-6648054a3cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing features from album_features.pkl...\n",
            "Processed Dataset features using ['color_hist']\n",
            "Feature dataframe\n",
            "                                          color_hist  \\\n",
            "0  [0.08430748, 0.0, 0.0012140276, 0.0004046759, ...   \n",
            "1  [0.99841475, 0.0, 0.0012881887, 0.0005991576, ...   \n",
            "2  [0.046410248, 0.0, 8.2433835e-05, 4.1216917e-0...   \n",
            "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
            "4  [0.22954293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
            "\n",
            "                          song_name  \n",
            "0            Mood (feat. iann dior)  \n",
            "1                          Dynamite  \n",
            "2                             Hawái  \n",
            "3  Savage Love (Laxed - Siren Beat)  \n",
            "4         Head & Heart (feat. MNEK)  \n",
            "Available features\n",
            "['color_hist']\n",
            "Recommendations for 'Shape of You':\n",
            "                                             color_hist            song_name\n",
            "282   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...          Galway Girl\n",
            "101   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...              Happier\n",
            "2452  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...            Barcelona\n",
            "356   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...  Supermarket Flowers\n",
            "399   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   Castle on the Hill\n",
            "\n",
            "Recommendations for playlist: ['Shape of You', 'Counting Stars', 'Havana']\n",
            "                                             color_hist  \\\n",
            "3298  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "669   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "399   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "2178  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "282   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "2465  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "3351  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "2147  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "101   [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "2447  [0.736289, 0.0, 0.0, 0.0, 0.0, 0.0, 4.1025745e...   \n",
            "\n",
            "                           song_name  \n",
            "3298                  Nancy Mulligan  \n",
            "669                             Dive  \n",
            "399               Castle on the Hill  \n",
            "2178  Hearts Don't Break Around Here  \n",
            "282                      Galway Girl  \n",
            "2465                     Save Myself  \n",
            "3351                  Bibia Be Ye Ye  \n",
            "2147      How Would You Feel (Paean)  \n",
            "101                          Happier  \n",
            "2447                         New Man  \n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "# Specify which features you want to use for the recommendation process\n",
        "available_features = ['color_hist']  # Modify as needed: ['color_hist'], ['resnet'], ['vgg'], ['font'], or combinations\n",
        "\n",
        "# Process entire dataset features, passing the desired techniques\n",
        "dataset_features = process_dataset_features(df, techniques=available_features)\n",
        "print(\"Processed Dataset features using\", available_features)\n",
        "\n",
        "# Recommendation for a single song\n",
        "target_song = 'Shape of You'\n",
        "song_recommendations = recommend_songs_by_cover(target_song, dataset_features, available_features=available_features)\n",
        "print(f\"Recommendations for '{target_song}':\")\n",
        "print(song_recommendations)\n",
        "\n",
        "# Playlist-based recommendation\n",
        "playlist = ['Shape of You', 'Counting Stars', 'Havana']\n",
        "playlist_recommendations = create_playlist_recommendation(playlist, dataset_features, available_features=available_features)\n",
        "print(\"\\nRecommendations for playlist:\", playlist)\n",
        "print(playlist_recommendations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZvHKGak_G1I"
      },
      "source": [
        "## Step 6: Visualization (Optional)\n",
        "\n",
        "To further explore and analyze the album cover similarities, visualization techniques can be applied. For example:\n",
        "\n",
        "### 1. Similarity Heatmaps\n",
        "   - A heatmap can be generated to visualize the cosine similarity matrix between the album cover features. This allows for an easy identification of songs that are similar to each other based on their album covers.\n",
        "\n",
        "### 2. t-SNE Plots\n",
        "   - t-SNE (t-Distributed Stochastic Neighbor Embedding) is a technique for dimensionality reduction that can be used to project the high-dimensional feature vectors into a 2D space. A t-SNE plot can help visualize how songs with similar album covers are grouped together.\n",
        "\n",
        "These visualizations can help to better understand the relationships between songs and the effectiveness of the recommendation system.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6c6-PY5_P-p"
      },
      "outputs": [],
      "source": [
        "def visualize_album_cover_similarities(features_df):\n",
        "    \"\"\"\n",
        "    Create a heatmap of album cover feature similarities\n",
        "    \"\"\"\n",
        "    # Compute similarity matrix for color histograms\n",
        "    color_similarity_matrix = cosine_similarity(\n",
        "        features_df['color_hist'].tolist(),\n",
        "        features_df['color_hist'].tolist()\n",
        "    )\n",
        "\n",
        "    # Plotting the heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(color_similarity_matrix, annot=False, cmap='viridis', xticklabels=False, yticklabels=False)\n",
        "    plt.title('Album Cover Color Similarity Heatmap')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize similarities\n",
        "visualize_album_cover_similarities(dataset_features)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}